üìå Vis√£o Geral
O Scientific Documents Explorer √© uma ferramenta avan√ßada de an√°lise de documentos cient√≠ficos que utiliza Processamento de Linguagem Natural (NLP) e Machine Learning para organizar, visualizar e explorar cole√ß√µes de artigos acad√™micos de forma inteligente.

Screenshot da Interface

‚ú® Principais Recursos
Processamento Autom√°tico de documentos em PDF, TXT e CSV

Clusteriza√ß√£o Inteligente de documentos por similaridade sem√¢ntica

Visualiza√ß√£o 3D Interativa dos clusters de documentos

Busca Sem√¢ntica que vai al√©m de palavras-chave

Detec√ß√£o de Anomalias para identificar documentos at√≠picos

Gera√ß√£o Autom√°tica de Insights sobre a cole√ß√£o de documentos

üõ†Ô∏è Tecnologias Utilizadas
Tecnologia	Finalidade
Python 3.10+	Linguagem principal
Streamlit	Interface web
ChromaDB	Banco de dados vetorial
Sentence Transformers	Gera√ß√£o de embeddings
UMAP	Redu√ß√£o de dimensionalidade
HDBSCAN	Clusteriza√ß√£o
Plotly	Visualiza√ß√£o 3D
NLTK	Processamento de texto
üöÄ Como Executar o Projeto
Pr√©-requisitos
Python 3.10 ou superior

Pip instalado

Instala√ß√£o
Clone o reposit√≥rio:

bash
git clone https://github.com/erikbarros14/capstone-Scientific-Documents/tree/main
cd scientific-documents-explorer
Crie e ative um ambiente virtual (recomendado):

bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate  # Windows
Instale as depend√™ncias:

bash
pip install -r requirements.txt
Baixe os modelos necess√°rios:

bash
python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('all-MiniLM-L6-v2')"
Execu√ß√£o
bash
streamlit run main.py
O aplicativo estar√° dispon√≠vel em http://localhost:8501

üîç Funcionamento Detalhado
1. Ingest√£o de Documentos
O sistema processa tr√™s tipos de arquivos:

PDF: Extrai texto com PyPDF2

TXT: L√™ conte√∫do diretamente

CSV: Trata cada linha como documento separado


# Trecho do ingest.py (linhas 58-99)
def process_file(self, filepath):
    if filepath.endswith('.pdf'):
        text = self._extract_from_pdf(filepath)
    elif filepath.endswith('.txt'):
        text = self._read_text_file(filepath)
    elif filepath.endswith('.csv'):
        text = self._process_csv(filepath)
    return self._clean_text(text)
2. Gera√ß√£o de Embeddings
Utiliza o modelo all-MiniLM-L6-v2 para criar representa√ß√µes vetoriais de 384 dimens√µes:

# Trecho do ingest.py (linhas 8-44)
def generate_embedding(self, text):
    model = SentenceTransformer('all-MiniLM-L6-v2')
    return model.encode(text)
3. Clusteriza√ß√£o
Combina UMAP para redu√ß√£o dimensional e HDBSCAN para clusteriza√ß√£o:

# Trecho do cluster_viz.py (linhas 10-24)
def process_documents(self, embeddings):
    umap_embeddings = umap.UMAP(n_components=3).fit_transform(embeddings)
    clusters = hdbscan.HDBSCAN(min_cluster_size=5).fit_predict(umap_embeddings)
    anomalies = self._detect_anomalies(umap_embeddings)
    return clusters, umap_embeddings, anomalies
4. Visualiza√ß√£o Interativa
Interface constru√≠da com Streamlit e Plotly:


# Trecho do main.py (linhas 148-178)
def visualize_clusters(self, embeddings, clusters, documents, anomalies):
    fig = px.scatter_3d(
        x=embeddings[:,0], y=embeddings[:,1], z=embeddings[:,2],
        color=clusters, hover_text=documents
    )
    fig.update_traces(marker=dict(size=5))
    return fig
üìä Demonstra√ß√£o
Upload de Documentos:

Selecione m√∫ltiplos arquivos PDF, TXT ou CSV

O sistema processar√° automaticamente

Explora√ß√£o Visual:

Documentos similares aparecem agrupados no espa√ßo 3D

Clusters s√£o coloridos automaticamente

Anomalias aparecem destacadas

Busca Sem√¢ntica:

Digite um conceito (ex: "machine learning")

O sistema retorna documentos relacionados semanticamente

Filtros:

Filtre por tipo de arquivo, cluster ou tamanho do texto
